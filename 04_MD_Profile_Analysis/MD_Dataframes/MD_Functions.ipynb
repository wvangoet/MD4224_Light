{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MD Analysis functions for MD4224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tImporting MD Analysis functions for MD4224\n",
      "Version 0.03. This is the latest version.\n",
      "Please help me to improve it reporting bugs to guido.sterbini@cern.ch.\n",
      "Your platform is Linux-3.10.0-1127.10.1.el7.x86_64-x86_64-with-centos-7.7.1908-Core\n",
      "Your folder is /eos/home-h/harafiqu/SWAN_projects/PS/From_Scratch\n",
      "Your IP is 172.17.0.14\n",
      "2020-08-14 13:34:31\n"
     ]
    }
   ],
   "source": [
    "print '\\n\\tImporting MD Analysis functions for MD4224'\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import glob\n",
    "import pickle\n",
    "#import imageio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio \n",
    "\n",
    "sys.path.append('/eos/user/s/sterbini/MD_ANALYSIS/public/')\n",
    "sys.path.append('/eos/project/l/liu/Toolbox/')\n",
    "\n",
    "from myToolbox import *\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.lines import Line2D\n",
    "from math import log10, floor\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.gridspec as gridspec    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_directory(path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % path)\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % path)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe from saved matlab MD files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fromMatlabToDataFrame(listing, listOfVariableToAdd, verbose=False, matlabFullInfo=False):\n",
    "    listOfVariableToAdd=list(set(listOfVariableToAdd))\n",
    "    myDataFrame=pnd.DataFrame({})\n",
    "    cycleStamp=[]\n",
    "    cycleStampHuman=[]\n",
    "    PLS_matlab=[]\n",
    "    matlabObject=[]\n",
    "    matlabFilePath=[]\n",
    "    for j in listOfVariableToAdd:\n",
    "        exec(j.replace('.','_')+'=[]')\n",
    "    for i in listing:\n",
    "        if verbose:\n",
    "            print(i)\n",
    "        data=myToolbox.japcMatlabImport(i);\n",
    "        if matlabFullInfo:\n",
    "            matlabObject.append(data)\n",
    "        #to correct\n",
    "        localCycleStamp=np.nanmax(data.headerCycleStamps);\n",
    "        deltaLocal_UTC=datetime.datetime.fromtimestamp(localCycleStamp/1e9)-datetime.datetime.utcfromtimestamp(localCycleStamp/1e9)\n",
    "        utcCycleStamp=localCycleStamp+deltaLocal_UTC.total_seconds()*1e9\n",
    "        cycleStamp.append(utcCycleStamp)\n",
    "        aux=myToolbox.unixtime2datetimeVectorize(np.nanmax(data.headerCycleStamps)/1e9)\n",
    "        cycleStampHuman.append(aux.tolist())\n",
    "        PLS_matlab.append(data.cycleName)\n",
    "        matlabFilePath.append(os.path.abspath(i))\n",
    "        for j in listOfVariableToAdd:\n",
    "            if hasattr(data,j.split('.')[0]):\n",
    "                exec(j.replace('.','_') + '.append(data.' + j + ')')\n",
    "            else:\n",
    "                exec(j.replace('.','_') + '.append(np.nan)')\n",
    "    myDataFrame['cycleStamp']=pnd.Series(cycleStamp,cycleStampHuman)\n",
    "    myDataFrame['matlabPLS']=pnd.Series(PLS_matlab,cycleStampHuman)\n",
    "    myDataFrame['matlabFilePath']=pnd.Series(matlabFilePath,cycleStampHuman)\n",
    "    if matlabFullInfo:\n",
    "        myDataFrame['matlabFullInfo']=pnd.Series(matlabObject,cycleStampHuman)\n",
    "    for j in listOfVariableToAdd:\n",
    "        exec('myDataFrame[\\'' + j + '\\']=pnd.Series(' +j.replace('.','_')+ ',cycleStampHuman)')    #myDataFrame=pnd.DataFrame({j:aux,\n",
    "    return myDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate maximum intensity, losses, and ratio from dataframe MD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensity_df(ndf,start=85,end=1185):\n",
    "    df=ndf.copy()\n",
    "    def losses(a):\n",
    "        try:\n",
    "            b=(a[start]-a[end])/a[start]*100 \n",
    "        except:\n",
    "            b=np.nan\n",
    "        return b\n",
    "    def ratio(a):\n",
    "        try:\n",
    "            c=a[end]/a[start]\n",
    "        except:\n",
    "            c=np.nan\n",
    "        return c\n",
    "    def max_intensity(a):\n",
    "        try:\n",
    "            d=np.max(a)\n",
    "        except:\n",
    "            d=np.nan\n",
    "        return d*1E10\n",
    "    df['intensity']=df['PR_BCT_ST.Samples.value.samples'].apply(max_intensity)\n",
    "    df['losses']=df['PR_BCT_ST.Samples.value.samples'].apply(losses)\n",
    "    df['ratio']=df['PR_BCT_ST.Samples.value.samples'].apply(ratio)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from Timber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(year=2018,date=4,month=9,hour=8,minutes=20,span=8,user='CPS%MD1',WS='65.H'):\n",
    "    t1=datetime.datetime(year,month,date,hour,minutes)\n",
    "    t2=t1+datetime.timedelta(hours=span)\n",
    "    CALS=['PR.BWS.{}_ROT:PROF_DATA_IN'.format(WS),  'PR.BWS.{}_ROT:PROF_POSITION_IN'.format(WS),  'PR.BWS.{}_ROT:ACQ_DELAY'.format(WS), 'PR.BCT.LT:SAMPLES']\n",
    "    df=myToolbox.fromTimberToDataFrame(CALS,t1,t2,fundamental=user)\n",
    "    return  df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian fits for 3, 4, and 5 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_3_parameters(x, A, mu, sig):\n",
    "    \"\"\"gaussian_3_parameter(x, m, A, mu, sig)\"\"\"\n",
    "    return A/np.sqrt(2*np.pi)/sig*np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
    "\n",
    "def gaussian_4_parameters(x, m, A, mu, sig):\n",
    "    \"\"\"gaussian_4_parameter(x, m, A, mu, sig)\"\"\"\n",
    "    return m*x+A/np.sqrt(2*np.pi)/sig*np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
    "\n",
    "def gaussian_5_parameters(x, c, m, A, mu, sig):\n",
    "    \"\"\"gaussian_5_parameter(x, c, m, A, mu, sig)\"\"\"\n",
    "    return c+m*x+A/np.sqrt(2*np.pi)/sig*np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate second moment of a distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_moment(values, weights):\n",
    "    weighted_average = np.average(values, weights=weights)\n",
    "    second_moment = np.sqrt(np.average((values-weighted_average)**2, weights=weights))\n",
    "    return (second_moment)\n",
    "\n",
    "def second_moment_2(values, weights, sig, n_sigmas=6.):\n",
    "    a=np.where((values<n_sigmas*sig) & (values>-n_sigmas*sig))[0]\n",
    "    values=values[a]\n",
    "    weights=weights[a]    \n",
    "    weighted_average = np.average(values, weights=weights)\n",
    "    second_moment = np.sqrt(np.average((values-weighted_average)**2, weights=weights))\n",
    "    return (second_moment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a svipy.savgol filter to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered(a):\n",
    "    try:\n",
    "        b=(scipy.signal.savgol_filter(a,15,1))\n",
    "    except:\n",
    "        b=a\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi step filtering of wirescanner profiles to extract standard deviation sigma and second moment mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Multi_filter(ndf, with_plot = False, WS = '65.H', sig_limit_mm=10, smooth = False):\n",
    "    \n",
    "    df = ndf.copy()\n",
    "    \n",
    "    position_label = 'PR.BWS.'+WS+'_ROT:PROF_POSITION_IN'\n",
    "    profile_label = 'PR.BWS.'+WS+'_ROT:PROF_DATA_IN'\n",
    "    \n",
    "    window = 40    \n",
    "    \n",
    "    # Arrays to hold dataframe data. Appended to dataframe at the end of the loop.\n",
    "    mu_5 = []\n",
    "    sigma_5 = []\n",
    "    A_5 = []\n",
    "    m_5 = []\n",
    "    c_5 = []\n",
    "    sig_err_5 = []\n",
    "    \n",
    "    mu_3 = []\n",
    "    sigma_3 = []\n",
    "    A_3 = []\n",
    "    sig_err_3 = []\n",
    "    \n",
    "    mom_2nd = []\n",
    "    \n",
    "    filtered_profiles = []\n",
    "    filtered_positions = []\n",
    "    \n",
    "    failed_rows = []\n",
    "    \n",
    "    new_new_X=[]\n",
    "    \n",
    "    # Iterate over dataframe\n",
    "    for j in range(0, len(df), 1):\n",
    "        print '\\nMulti_filter row ', j\n",
    "        \n",
    "# 5 parameter Gaussian fit to find mean and sigma\n",
    "#------------------------------------------------\n",
    "    \n",
    "        data = []\n",
    "        # Filter the data (scipy.signal.savgol_filter)\n",
    "        if smooth: data = filtered(df[profile_label].iloc()[j])    \n",
    "        else:data = df[profile_label].iloc()[j]\n",
    "            \n",
    "        X = df[position_label].iloc()[j]/1000.\n",
    "        Y = data\n",
    "        indx_max = np.argmax(Y)\n",
    "        mu0 = X[indx_max]\n",
    "        x_tmp = X\n",
    "        y_tmp = Y\n",
    "        offs0 = min(y_tmp)\n",
    "        ampl = max(y_tmp)-offs0\n",
    "        x1 = x_tmp[np.searchsorted(y_tmp[:window], offs0+ampl/2)]\n",
    "        x2 = x_tmp[np.searchsorted(-y_tmp[window:], -offs0+ampl/2)]\n",
    "        FWHM = x2-x1\n",
    "        #sigma0 = np.abs(2*FWHM/2.355)\n",
    "        sigma0 = 5\n",
    "        ampl *= np.sqrt(2*np.pi)*sigma0\n",
    "        slope = 0\n",
    "        \n",
    "        popt5 = []\n",
    "        pcov5 = []    \n",
    "\n",
    "        popt5, pcov5 = curve_fit(gaussian_5_parameters, X, data, p0 =[offs0, slope, ampl, mu0, sigma0])\n",
    "        result5 = gaussian_5_parameters(X, popt5[0], popt5[1], popt5[2], popt5[3], popt5[4])\n",
    "\n",
    "        fit_c_5 = popt5[0]\n",
    "        fit_m_5 = popt5[1]\n",
    "        fit_A_5 = popt5[2]\n",
    "        fit_mean_5 = popt5[3]\n",
    "        fit_sigma_5 = abs(popt5[4])\n",
    "        \n",
    "        c_5.append(np.array(popt5[0]))\n",
    "        m_5.append(np.array(popt5[1]))\n",
    "        A_5.append(np.array(popt5[2]))\n",
    "        mu_5.append(np.array(popt5[3]))\n",
    "        sigma_5.append(abs(np.array(abs(popt5[4]))))\n",
    "        sig_err_5.append(np.sqrt(np.diag(pcov5[4])[4][4]))\n",
    "        \n",
    "        print '5 parameter fit sigma = ', fit_sigma_5 , ' +/- ', np.sqrt(np.diag(pcov5[4]))[4][4]\n",
    "    \n",
    "        if fit_sigma_5 > sig_limit_mm:\n",
    "            \n",
    "            print '\\n\\tinitial guess: mu0', mu0\n",
    "            print '\\tinitial guess: offs0', offs0\n",
    "            print '\\tinitial guess: ampl', ampl\n",
    "            print '\\tinitial guess: slope', slope\n",
    "            print '\\tinitial guess: sigma0', sigma0\n",
    "            \n",
    "            result0 = gaussian_5_parameters(X, offs0, slope, ampl, mu0, sigma0)\n",
    "            \n",
    "            fig, ax1 = plt.subplots(figsize=(8, 4), dpi= 200, facecolor='w', edgecolor='k');\n",
    "\n",
    "            plt.plot(X, df[profile_label].iloc()[j], label='raw');\n",
    "            plt.plot(X, result5, label='5 param fit');\n",
    "            plt.plot(X, result0, label='initial param fit');\n",
    "\n",
    "            tit = 'WS profile & fit ' + str(j);\n",
    "            savename = 'MD4224_HB_Vertical_Multifit_' + str(j);\n",
    "\n",
    "            plt.title(tit);\n",
    "            plt.ylabel('Profile [-]');\n",
    "            plt.xlabel('Position [mm]');\n",
    "            plt.legend();            \n",
    "            plt.grid();\n",
    "            fig.savefig(savename);    \n",
    "            plt.close();\n",
    "            \n",
    "            # Set empty array values for completeness - cannot set dataframe with missing values\n",
    "            filtered_profiles.append(np.nan)\n",
    "            filtered_positions.append(np.nan)\n",
    "            \n",
    "            failed_rows.append(j)\n",
    "\n",
    "            mom_2nd.append(np.nan)\n",
    "\n",
    "            c_5.append(np.nan)\n",
    "            m_5.append(np.nan)\n",
    "            A_5.append(np.nan)\n",
    "            mu_5.append(np.nan)\n",
    "            sigma_5.append(np.nan)\n",
    "            sig_err_5.append(np.nan)\n",
    "\n",
    "            A_3.append(np.nan)\n",
    "            mu_3.append(np.nan)\n",
    "            sigma_3.append(np.nan)\n",
    "            sig_err_3.append(np.nan)        \n",
    "  \n",
    "            \n",
    "        # Simple filter for negative sigma (fit didn't work)\n",
    "        elif fit_sigma_5 < sig_limit_mm:\n",
    "            \n",
    "# Consider only data between +/-(6 sigma + mean)\n",
    "#------------------------------------------------\n",
    "            new_X = []\n",
    "            new_Y = []        \n",
    "\n",
    "            # Iterate over data\n",
    "            for i in xrange(len(Y)): # Append data if inside cut window\n",
    "                if (X[i] < (6*fit_sigma_5 + fit_mean_5)) and (X[i] > (-6*fit_sigma_5 + fit_mean_5)):\n",
    "\n",
    "# Remove Slope and Offset\n",
    "#------------------------------------------------               \n",
    "                    new_X.append(X[i])\n",
    "                    new_Y.append(Y[i] - (fit_m_5*X[i] + fit_c_5))\n",
    "\n",
    "# 3 parameter Gaussian fit to centre\n",
    "#------------------------------------------------\n",
    "\n",
    "            popt3 = []\n",
    "            pcov3 = []   \n",
    "            popt3, pcov3 = curve_fit(gaussian_3_parameters, new_X, new_Y, p0 =[fit_A_5, fit_mean_5, fit_sigma_5])\n",
    "            result3 = gaussian_3_parameters(new_X, popt3[0], popt3[1], popt3[2])\n",
    "\n",
    "            fit_A_3 = popt3[0]\n",
    "            fit_mean_3 = popt3[1]\n",
    "            fit_sigma_3 = popt3[2]\n",
    "\n",
    "            A_3.append(np.array(popt3[0]))\n",
    "            mu_3.append(np.array(popt3[1]))\n",
    "            sigma_3.append(np.array(abs(popt3[2])))\n",
    "            sig_err_3.append(np.sqrt(np.diag(pcov3[2]))[2][2])     \n",
    "\n",
    "            print '3 parameter fit sigma = ', popt3[2] , ' +/- ', np.sqrt(np.diag(pcov3[2]))[2][2]\n",
    "\n",
    "# Threshold ?\n",
    "#------------------------------------------------\n",
    "\n",
    "# 2nd moment\n",
    "#------------------------------------------------\n",
    "            # Shift centre\n",
    "            new_new_X = new_X - fit_mean_3\n",
    "\n",
    "            second_mom = second_moment(new_new_X, new_Y)\n",
    "\n",
    "            mom_2nd.append(second_mom)\n",
    "\n",
    "            print 'Second moment = ', second_mom        \n",
    "\n",
    "            # Append to dataframe later\n",
    "            filtered_positions.append(new_new_X)\n",
    "            filtered_profiles.append(new_Y)       \n",
    "\n",
    "# Plot\n",
    "#------------------------------------------------      \n",
    "            if with_plot:\n",
    "                fig, ax1 = plt.subplots(figsize=(8, 4), dpi= 200, facecolor='w', edgecolor='k');\n",
    "\n",
    "                plt.plot(X, df[profile_label].iloc()[j], label='raw');\n",
    "                plt.plot(X, result5, label='5 param fit');\n",
    "                plt.plot(new_new_X, result3, label='3 param fit' );\n",
    "                plt.plot(new_new_X, new_Y, label='filtered');\n",
    "\n",
    "                tit = 'WS profile & fit ' + str(j);\n",
    "                savename = 'MD4224_HB_Vertical_Multifit_' + str(j);\n",
    "\n",
    "                plt.title(tit);\n",
    "                plt.ylabel('Profile [-]');\n",
    "                plt.xlabel('Position [mm]');\n",
    "                plt.legend();            \n",
    "                plt.grid();\n",
    "                fig.savefig(savename);\n",
    "                plt.close();\n",
    "\n",
    "    # Set values in dataframe   \n",
    "    \n",
    "#     df['5sig '+WS[-1]] = sigma_5\n",
    "#     df['5sig err'+WS[-1]] = sig_err_5\n",
    "#     df['5A '+WS[-1]] = A_5\n",
    "#     df['5mu '+WS[-1]] = mu_5\n",
    "#     df['5m '+WS[-1]] = m_5\n",
    "#     df['5c '+WS[-1]] = c_5\n",
    "    \n",
    "#     df['3sig '+WS[-1]] = sigma_3\n",
    "#     df['3sig err'+WS[-1]] = sig_err_3\n",
    "#     df['3A '+WS[-1]] = A_3\n",
    "#     df['3mu '+WS[-1]] = mu_3\n",
    "    \n",
    "    df['2ndMoment '+WS[-1]] = mom_2nd   \n",
    "    \n",
    "    df['sig '+WS[-1]] = sigma_3\n",
    "    df['sig err'+WS[-1]] = sig_err_3\n",
    "    df['A '+WS[-1]] = A_3\n",
    "    df['mu '+WS[-1]] = mu_3\n",
    "    \n",
    "    df['position '+WS[-1]] = filtered_positions\n",
    "    df['profile '+WS[-1]] = filtered_profiles\n",
    "    \n",
    "    print 'failed rows = ', failed_rows\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi step filtering of simulation profiles to extract standard deviation sigma and second moment mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Multi_filter_sim(ndf, with_plot = False, WS = '65.H', sig_limit_mm=10, smooth = False):\n",
    "    \n",
    "    df = ndf.copy()\n",
    "    \n",
    "    position_label = 'PR.BWS.'+WS+'_ROT:PROF_POSITION_IN'\n",
    "    profile_label = 'PR.BWS.'+WS+'_ROT:PROF_DATA_IN'\n",
    "    \n",
    "    window = 40    \n",
    "    \n",
    "    # Arrays to hold dataframe data. Appended to dataframe at the end of the loop.\n",
    "    mu_5 = []\n",
    "    sigma_5 = []\n",
    "    A_5 = []\n",
    "    m_5 = []\n",
    "    c_5 = []\n",
    "    sig_err_5 = []\n",
    "    \n",
    "    mu_3 = []\n",
    "    sigma_3 = []\n",
    "    A_3 = []\n",
    "    sig_err_3 = []\n",
    "    \n",
    "    mom_2nd = []\n",
    "    \n",
    "    filtered_profiles = []\n",
    "    filtered_positions = []\n",
    "    \n",
    "    failed_rows = []\n",
    "    \n",
    "    new_new_X=[]\n",
    "    \n",
    "    # Iterate over dataframe\n",
    "    for j in range(0, len(df), 1):\n",
    "        print '\\nMulti_filter row ', j\n",
    "        \n",
    "# 5 parameter Gaussian fit to find mean and sigma\n",
    "#------------------------------------------------\n",
    "\n",
    "        data = []\n",
    "        # Filter the data (scipy.signal.savgol_filter)\n",
    "        if smooth: data = filtered(df[profile_label].iloc()[j])    \n",
    "        else:data = df[profile_label].iloc()[j]\n",
    "            \n",
    "        #X = df[position_label].iloc()[j]/1000.\n",
    "        X = df[position_label].iloc()[j]*1000\n",
    "        Y = data\n",
    "        indx_max = np.argmax(Y)\n",
    "        mu0 = X[indx_max]\n",
    "        x_tmp = X\n",
    "        y_tmp = Y\n",
    "        offs0 = min(y_tmp)\n",
    "        ampl = max(y_tmp)-offs0\n",
    "        x1 = x_tmp[np.searchsorted(y_tmp[:window], offs0+ampl/2)]\n",
    "        x2 = x_tmp[np.searchsorted(-y_tmp[window:], -offs0+ampl/2)]\n",
    "        FWHM = x2-x1\n",
    "        sigma0 = np.abs(2*FWHM/2.355)\n",
    "        #sigma0 = 5\n",
    "        ampl *= np.sqrt(2*np.pi)*sigma0\n",
    "        slope = 0\n",
    "        \n",
    "        ampl = peakfinder(np.array(bins_[:-1]), np.array(data))\n",
    "                        \n",
    "        print '\\n\\tinitial guess: mu0', mu0\n",
    "        print '\\tinitial guess: offs0', offs0\n",
    "        print '\\tinitial guess: ampl', ampl\n",
    "        print '\\tinitial guess: slope', slope\n",
    "        print '\\tinitial guess: sigma0', sigma0\n",
    "        \n",
    "        popt3 = []\n",
    "        pcov3 = []   \n",
    "        popt3, pcov3 = curve_fit(gaussian_3_parameters, X, Y, p0 =[ampl, mu0, sigma0])\n",
    "        result3 = gaussian_3_parameters(X, popt3[0], popt3[1], popt3[2])\n",
    "\n",
    "        fit_A_3 = popt3[0]\n",
    "        fit_mean_3 = popt3[1]\n",
    "        fit_sigma_3 = popt3[2]\n",
    "\n",
    "        A_3.append(np.array(popt3[0]))\n",
    "        mu_3.append(np.array(popt3[1]))\n",
    "        sigma_3.append(np.array(abs(popt3[2])))\n",
    "        sig_err_3.append(np.sqrt(np.diag(pcov3[2]))[2][2])     \n",
    "\n",
    "        print '3 parameter fit sigma = ', popt3[2] , ' +/- ', np.sqrt(np.diag(pcov3[2]))[2][2]\n",
    "                \n",
    "# 2nd moment\n",
    "#------------------------------------------------\n",
    "        # Shift centre\n",
    "        new_new_X = X - fit_mean_3\n",
    "        print 'Removing centre shift of ', fit_mean_3\n",
    "        \n",
    "        filtered_positions.append(new_new_X)\n",
    "        filtered_profiles.append(Y)    \n",
    "\n",
    "        second_mom = second_moment(new_new_X, Y)\n",
    "\n",
    "        mom_2nd.append(second_mom)\n",
    "\n",
    "        print 'Second moment = ', second_mom     \n",
    "        \n",
    "        # Plot\n",
    "#------------------------------------------------      \n",
    "        if with_plot:\n",
    "            fig, ax1 = plt.subplots(figsize=(8, 4), dpi= 200, facecolor='w', edgecolor='k');\n",
    "\n",
    "            plt.plot(X, df[profile_label].iloc()[j], label='raw');\n",
    "            plt.plot(new_new_X, result3, label='3 param fit' );\n",
    "            plt.plot(new_new_X, Y, label='filtered');\n",
    "\n",
    "            tit = 'WS profile & fit ' + str(j);\n",
    "            savename = 'MD4224_HB_Vertical_Multifit_' + str(j);\n",
    "\n",
    "            plt.title(tit);\n",
    "            plt.ylabel('Profile [-]');\n",
    "            plt.xlabel('Position [mm]');\n",
    "            plt.legend();            \n",
    "            plt.grid();\n",
    "            fig.savefig(savename);\n",
    "            plt.close();\n",
    "             \n",
    "    df['2ndMoment '+WS[-1]] = mom_2nd   \n",
    "    \n",
    "    df['sig '+WS[-1]] = sigma_3\n",
    "    df['sig err'+WS[-1]] = sig_err_3\n",
    "    df['A '+WS[-1]] = A_3\n",
    "    df['mu '+WS[-1]] = mu_3\n",
    "    \n",
    "    df['position '+WS[-1]] = filtered_positions\n",
    "    df['profile '+WS[-1]] = filtered_profiles\n",
    "    \n",
    "    print 'failed rows = ', failed_rows\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core filter removes tails and fits gaussian to wirescanner profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Core_filter(ndf, with_plot = True, WS = '65.H', sig_limit_mm=10, smooth = False):\n",
    "    \n",
    "    df = ndf.copy()\n",
    "    \n",
    "    position_label = 'position H'\n",
    "    profile_label = 'profile H'\n",
    "    window = 40\n",
    "    \n",
    "    \n",
    "    mu_3 = []\n",
    "    sigma_3 = []\n",
    "    A_3 = []\n",
    "    sig_err_3 = []\n",
    "    \n",
    "    mom_2nd = []\n",
    "    \n",
    "    # Iterate over dataframe\n",
    "    for j in range(0, len(df), 1):\n",
    "        print '\\nCore_filter row ', j    \n",
    "    \n",
    "        y_data = df[profile_label].iloc()[j]\n",
    "        x_data = df[position_label].iloc()[j]\n",
    "        indx_max = np.argmax(y_data)  \n",
    "        peak = y_data[indx_max]\n",
    "        \n",
    "#         print '\\nPeak magnitude ', peak, 'found at index ', indx_max\n",
    "        \n",
    "        quart_len_x_dat = int(len(x_data)/4)\n",
    "        \n",
    "#         print '\\nUsing indices', int(indx_max-quart_len_x_dat), ' to ', int(indx_max+quart_len_x_dat)\n",
    "        \n",
    "        # Use only half of the data, around the peak        \n",
    "#         half_peak_indices = find_half_peak_indices(x_data, y_data)\n",
    "        # equivalent\n",
    "        half_peak_indices = find_factor_of_peak_indices(x_data, y_data, 0.5, verbose=True)\n",
    "        \n",
    "        X = x_data[half_peak_indices[0] : half_peak_indices[1]]\n",
    "#         X = X/1000\n",
    "        Y = y_data[half_peak_indices[0] : half_peak_indices[1]]\n",
    "        \n",
    "        indx_max = np.argmax(Y)        \n",
    "        mu0 = X[indx_max]\n",
    "        x_tmp = X\n",
    "        y_tmp = Y\n",
    "        offs0 = min(y_tmp)\n",
    "        ampl = max(y_tmp)-offs0\n",
    "#         x1 = x_tmp[np.searchsorted(y_tmp[:window], offs0+ampl/2)]\n",
    "#         x2 = x_tmp[np.searchsorted(-y_tmp[window:], -offs0+ampl/2)]\n",
    "#         FWHM = x2-x1\n",
    "        #sigma0 = np.abs(2*FWHM/2.355)\n",
    "        sigma0 = 1\n",
    "        ampl *= np.sqrt(2*np.pi)*sigma0\n",
    "        slope = 0\n",
    "    \n",
    "        popt3 = []\n",
    "        pcov3 = []   \n",
    "        \n",
    "        try:\n",
    "            popt3, pcov3 = curve_fit(gaussian_3_parameters, X, Y, p0 =[ampl, mu0, sigma0])\n",
    "\n",
    "            fit_A_3 = popt3[0]\n",
    "            fit_mean_3 = popt3[1]\n",
    "            fit_sigma_3 = popt3[2]\n",
    "\n",
    "            A_3.append(np.array(popt3[0]))\n",
    "            mu_3.append(np.array(popt3[1]))\n",
    "            sigma_3.append(np.array(abs(popt3[2])))\n",
    "            sig_err_3.append(np.sqrt(np.diag(pcov3[2]))[2][2])   \n",
    "            \n",
    "            print '3 parameter fit sigma = ', popt3[2] , ' +/- ', np.sqrt(np.diag(pcov3[2]))[2][2]\n",
    "# Plot\n",
    "#------------------------------------------------      \n",
    "            if with_plot:\n",
    "                fig, ax1 = plt.subplots(figsize=(8, 4), dpi= 200, facecolor='w', edgecolor='k');\n",
    "\n",
    "                x_dat = np.linspace(-20, 20, 1000)\n",
    "                result3 = gaussian_3_parameters(x_dat, popt3[0], popt3[1], popt3[2])\n",
    "\n",
    "                plt.plot(df[position_label].iloc()[j], df[profile_label].iloc()[j], label='filtered data');\n",
    "                plt.plot(X, Y, label='raw core data');\n",
    "                plt.plot(x_dat, result3, label='3 param core fit' );\n",
    "\n",
    "                tit = 'WS profile & fit ' + str(j);\n",
    "                savename = 'MD4224_HB_Vertical_Corefit_' + str(j);\n",
    "\n",
    "                plt.title(tit);\n",
    "                plt.ylabel('Profile [-]');\n",
    "                plt.xlabel('Position [mm]');\n",
    "                plt.legend();            \n",
    "                plt.grid();\n",
    "                fig.savefig(savename);\n",
    "                plt.close();            \n",
    "            \n",
    "        except:            \n",
    "            \n",
    "            print '3 parameter fit not found'\n",
    "                        \n",
    "            result3 = 'NaN'\n",
    "\n",
    "            fit_A_3 = 'NaN'\n",
    "            fit_mean_3 = 'NaN'\n",
    "            fit_sigma_3 = 'NaN'\n",
    "\n",
    "            A_3.append('NaN')\n",
    "            mu_3.append('NaN')\n",
    "            sigma_3.append('NaN')\n",
    "            sig_err_3.append('NaN')   \n",
    "        \n",
    "        second_mom = second_moment(X, Y)\n",
    "\n",
    "        mom_2nd.append(second_mom)\n",
    "    \n",
    "    df['Core 2ndMoment '+WS[-1]] = mom_2nd   \n",
    "    \n",
    "    df['Core sig '+WS[-1]] = sigma_3\n",
    "    df['Core sig err'+WS[-1]] = sig_err_3\n",
    "    df['Core A '+WS[-1]] = A_3\n",
    "    df['Core mu '+WS[-1]] = mu_3\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def span_range(df,myFiles=None):\n",
    "    if myFiles:\n",
    "        span=[i for i in xrange(len(df)) if datetime.datetime.strptime(myFiles[0][-27:-4], '%Y.%m.%d.%H.%M.%S.%f')<df.index[i]<datetime.datetime.strptime(myFiles[-1][-27:-4], '%Y.%m.%d.%H.%M.%S.%f')]\n",
    "    else:\n",
    "        span=xrange(len(df))\n",
    "    return span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optics functions at wirescanner locations\n",
    "TODO: redo simulation (SC) optics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PS_WSoptics(tunex, tuney, WS='65.V', verbose=False):\n",
    "    result = 0\n",
    "    \n",
    "    #Vertical\n",
    "    if WS[-1]=='V':\n",
    "        Qy = [6.1, 6.11, 6.12, 6.13, 6.14, 6.15, 6.16, 6.17, 6.18, 6.19, 6.2, 6.21, 6.22, 6.23, 6.24]\n",
    "        beta_x_ptc = [12.3917987, 12.40432702, 12.41682545, 12.42928263, 12.44169062, 12.45404385, 12.46633837, 12.4785714, 12.490741, 12.50284583, 12.51488502, 12.52685805, 12.53876466, 12.55060479, 12.56237852]\n",
    "        beta_y_ptc = [23.63758073, 23.28587814, 23.0095329, 22.78949387, 22.6124809, 22.4689646, 22.35193576, 22.25612762, 22.17750836, 22.11294062, 22.05994741, 22.01654769, 21.98113853, 21.95240934, 21.9292783]\n",
    "        D_x_ptc = [2.656001885, 2.651032449, 2.646066748, 2.641109387, 2.636163621, 2.631231787, 2.626315585, 2.621416255, 2.61653471, 2.611671616, 2.606827458, 2.602002581, 2.597197226, 2.59241155, 2.587645646]\n",
    "        D_y_ptc = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "        \n",
    "        # HR Sims 28.10.19\n",
    "        Dx_V =  [2.7238641993955732, 2.7120860629004255, 2.6994508041931335, 2.6863440678031574, 2.672386228651023, 2.6580229615003876, 2.64314556738443, 2.6280882092976365, 2.6129041363713723, 2.59744005103213, 2.5818492232775934, 2.5662886921607866, 2.550424494135266, 2.5343524154736436, 2.51866641467657]\n",
    "        Dy_V =  [4.367816748122375e-05, 0.00035587086701217597, 0.0003660175570428406, 8.26174877194663e-06, -0.000191423682138625, 5.658288855341201e-06, 0.00014281744599578446, -2.878620105586677e-05, -9.647589487896772e-05, -9.090651784262011e-07, -4.668886732849038e-06, 1.4755109576529703e-05, 1.6328867913236533e-05, 2.007351627844793e-05, -1.1071869433949277e-05]\n",
    "        Beta_x_V =  [11.445953852723896, 11.510142057939072, 11.575929347922242, 11.643662666888034, 11.714421282518094, 11.78791904681883, 11.862932437305316, 11.936289107196501, 12.00850847462817, 12.081015850533856, 12.15156515013633, 12.221473527902477, 12.289860697803704, 12.355190394931768, 12.418258827986351]\n",
    "        Beta_y_V =  [28.911819899988416, 27.996762372437498, 27.171729802194253, 26.440881544797726, 25.790346611279418, 25.1990325491867, 24.686162791589517, 24.248284914152663, 23.890035080396505, 23.597342279733034, 23.360243624322617, 23.168868800433106, 23.007663535440482, 22.85906902131989, 22.73172392767982]\n",
    "        Alpha_x_V =  [0.021341472442704016, 0.02001299826083461, 0.018660752366609214, 0.017267348024435355, 0.015807353862269672, 0.014280173350249396, 0.012714813147292111, 0.011191659680433794, 0.00969925057116425, 0.008207509530218775, 0.006769923106013124, 0.00532764358669049, 0.0039347261542670275, 0.002608967925014358, 0.001333583103170329]\n",
    "        Alpha_y_V =  [-0.07838658779883619, -0.06186142706417254, -0.046655182336960525, -0.03289429996349511, -0.02035536261873128, -0.008852168427724847, 0.001332783765145378, 0.0101563197348924, 0.01754743094728221, 0.02371638294074064, 0.028870423806189226, 0.033184032486125795, 0.0368729594656826, 0.04018756918984884, 0.043056837363835844]\n",
    "\n",
    "        beta_x_int = interp1d(Qy, beta_x_ptc)\n",
    "        beta_y_int = interp1d(Qy, beta_y_ptc, kind='cubic')\n",
    "\n",
    "        D_y_int = interp1d(Qy, D_y_ptc)\n",
    "        \n",
    "        if tuney < 1:\n",
    "            tuney = 6 + tuney\n",
    "    \n",
    "        if tuney > 6.24:\n",
    "            result = {'Beta_x':beta_x_int(6.24), 'Beta_y':beta_y_int(6.24),'D_y': D_y_int(6.24)}\n",
    "        elif tuney < 6.10:\n",
    "            result = {'Beta_x':beta_x_int(6.10), 'Beta_y':beta_y_int(6.10),'D_y': D_y_int(6.10)}\n",
    "        else:\n",
    "            result = {'Beta_x':beta_x_int(tuney), 'Beta_y':beta_y_int(tuney),'D_y': D_y_int(tuney)}\n",
    "\n",
    "\n",
    "    #Horizontal\n",
    "    else:\n",
    "        # Data from simulations (PyORBIT bunch twiss analysis of tomo distn from nominal (6.21, 6.24) measured tomo)\n",
    "        Qx = [6.07, 6.08, 6.09, 6.1, 6.11, 6.12, 6.13, 6.14, 6.15, 6.16, 6.17, 6.18, 6.19, 6.2, 6.21]\n",
    "        \n",
    "        # HR Flat files with optimised lattice 28.10.19\n",
    "        beta_x_PTC = [19.91204908, 20.41311562, 20.80478841, 21.11699894, 21.36981083, 21.57714653, 21.74895351, 21.89251823, 22.01329345, 22.11543602, 22.20216651, 22.27601575, 22.33899757, 22.39273226, 22.43853628]\n",
    "        beta_y_PTC = [11.79735718, 11.79122428, 11.78512065, 11.77905419, 11.77302966, 11.76704997, 11.76111691, 11.75523152, 11.74939435, 11.74360562, 11.73786533, 11.73217331, 11.72652929, 11.7209329, 11.71538372]\n",
    "        D_x_PTC = [3.966338945, 3.890361791, 3.825040281, 3.768310512, 3.718497363, 3.674282576, 3.634635336, 3.598747003, 3.565978669, 3.53582111, 3.507864727, 3.481777062, 3.457285906, 3.434166539, 3.412232006]\n",
    "\n",
    "        # HR Sims 28.10.19\n",
    "        Q_x_H =  [6.07, 6.08, 6.09, 6.1, 6.11, 6.12, 6.13, 6.14, 6.15, 6.16, 6.17, 6.18, 6.19, 6.2, 6.21]\n",
    "        Dx_H =  [5.094041737639815, 4.745555457055128, 4.465376676611421, 4.243625666843309, 4.069281878600707, 3.9316158604113913, 3.820341066721708, 3.726204087526766, 3.6461483127488576, 3.5756765668001607, 3.5129668013633237, 3.4563946388233266, 3.404480149204493, 3.3564030388195856, 3.3116558798797184]\n",
    "        Dy_H =  [1.4750033030587474e-05, 6.467605854338345e-07, -1.0514917113366752e-05, 5.815755472624499e-06, 2.1595046605289424e-05, 5.908728772597862e-06, -9.255017467287862e-06, 1.0035542292204026e-05, 1.051816255640615e-05, -1.0728393759677672e-06, 3.9371025222305687e-07, -1.3797255912659215e-05, -1.766537470942474e-05, 7.172375722134988e-06, -1.61589132330799e-05]\n",
    "        Beta_x_H =  [16.042909156812588, 16.62273975494126, 17.13286856078035, 17.651410896775587, 18.244770290045892, 18.860894438903497, 19.472153382370056, 20.032653880308352, 20.511990757311683, 20.915624794555598, 21.252628685987624, 21.536855772793007, 21.777555988752145, 21.984198721771286, 22.16224322605364]\n",
    "        Beta_y_H =  [12.852875430115793, 12.806481183737281, 12.764126372010868, 12.71817556261556, 12.66659533313386, 12.614204327190516, 12.562485537918654, 12.511011335754496, 12.46091614678202, 12.415061158200734, 12.37174124057102, 12.332343891998581, 12.29524826325735, 12.259437535414815, 12.22398863524938]\n",
    "        Alpha_x_H =  [-0.1799963812314074, -0.16250508378742642, -0.14726737076320215, -0.13013227004799938, -0.10913504964040957, -0.08733278265339776, -0.066157270923998, -0.04741824001308929, -0.03178445318085828, -0.018811089794352556, -0.00804469380421407, 0.001044815888149088, 0.008787677241830502, 0.015467148688671589, 0.021290480152427866]\n",
    "        Alpha_y_H =  [0.11757328235199145, 0.11505359543830002, 0.11269850056765092, 0.1102547485782107, 0.10764803484390695, 0.10507045912893033, 0.10256356772387268, 0.10009810822812605, 0.09773741074883112, 0.09554658412728842, 0.09346903818791467, 0.09150872053178623, 0.08962272899550859, 0.08776747571710704, 0.08592254554093123]\n",
    "\n",
    "        beta_x_int = interp1d(Qx, beta_x_PTC, kind='cubic')\n",
    "        beta_y_int = interp1d(Qx, beta_y_PTC)        \n",
    "        D_x_int = interp1d(Qx, D_x_PTC)\n",
    "    \n",
    "        if tunex < 1:\n",
    "            tunex = 6 + tunex\n",
    "\n",
    "        if tunex > 6.21:\n",
    "            result = {'Beta_x':beta_x_int(6.21), 'Beta_y':beta_y_int(6.21),'D_x': D_x_int(6.21)}\n",
    "        elif tunex < 6.07:\n",
    "            result = {'Beta_x':beta_x_int(6.07), 'Beta_y':beta_y_int(6.07),'D_x': D_x_int(6.07)}\n",
    "        else:            \n",
    "            #print 'Horizontal PS_WSoptics: tune ', tunex, ', ', tuney\n",
    "            #print 'D_x = ', D_x_int(tunex)\n",
    "            result = {'Beta_x':beta_x_int(tunex), 'Beta_y':beta_y_int(tunex),'D_x': D_x_int(tunex)}\n",
    "            #print result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple 5 parameter gaussian fit of wirescanner data from Foteini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profiles(ndf,WS='65.H',myFiles=None, lim=40):\n",
    "    df=ndf.copy()\n",
    "    # play with these limits\n",
    "    #x=np.linspace(-40,40,1000)\n",
    "    x=np.linspace(-lim,lim,1000)\n",
    "    a=df.columns\n",
    "    if 'profile '+WS[-1] not in a:\n",
    "        df['profile '+WS[-1]]=df['PR.BWS.{}_ROT:PROF_DATA_IN'.format(WS)].apply(filtered)\n",
    "        df['position '+WS[-1]]=df['PR.BWS.{}_ROT:PROF_POSITION_IN'.format(WS)].values/1000.\n",
    "    if 'sig '+WS[-1] not in a:\n",
    "        df['sig '+WS[-1]]=np.nan\n",
    "        df['mu '+WS[-1]]=np.nan\n",
    "        df['c '+WS[-1]]=np.nan\n",
    "        df['A '+WS[-1]]=np.nan\n",
    "\n",
    "    span=span_range(df,myFiles=myFiles)\n",
    "    if np.isnan(df['sig '+WS[-1]].iloc[span]).all():\n",
    "        for i in span:\n",
    "            df['A '+WS[-1]].iloc[i], df['c '+WS[-1]].iloc[i], df['mu '+WS[-1]].iloc[i], df['sig '+WS[-1]].iloc[i] = makeGaussianFit_5_parameters(df['position '+WS[-1]].iloc[i], df['profile '+WS[-1]].iloc[i], for_df=True, window=lim)\n",
    "            try:\n",
    "                yz=scipy.interpolate.interp1d(df['position '+WS[-1]].iloc[i] - df['mu '+WS[-1]].iloc[i], df['profile '+WS[-1]].iloc[i] - df['c '+WS[-1]].iloc[i])(x)\n",
    "                if np.isnan(yz[0]):\n",
    "                    yz=np.nan\n",
    "            except:\n",
    "                yz = np.nan\n",
    "            df['profile '+WS[-1]].iloc[i]=yz\n",
    "            df['position '+WS[-1]].iloc[i]=x\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add optics parameters to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twiss(ndf,WS='65.H',myFiles=None, verbose=False):\n",
    "    df=ndf.copy()\n",
    "    a=df.columns\n",
    "    if 'betx' not in a:\n",
    "        df['betx']=np.nan\n",
    "    if 'bety' not in a:\n",
    "         df['bety']=np.nan\n",
    "    if 'dx' not in a:\n",
    "         df['dx']=np.nan\n",
    "    span=span_range(df,myFiles=myFiles)\n",
    "    for i in span:\n",
    "        df.loc[df.index[i],'betx']=PS_WSoptics( df['Qx'].iloc[i], df['Qy'].iloc[i], WS=WS, verbose=verbose )['Beta_x']\n",
    "        df.loc[df.index[i],'bety']=PS_WSoptics( df['Qx'].iloc[i], df['Qy'].iloc[i], WS=WS, verbose=verbose )['Beta_y']\n",
    "            \n",
    "            \n",
    "        if WS[-1]=='V': df.loc[df.index[i],'dy']=PS_WSoptics( df['Qx'].iloc[i], df['Qy'].iloc[i], WS=WS, verbose=verbose )['D_y']\n",
    "        elif WS[-1]=='H':\n",
    "            #print 'result = ', (PS_WSoptics( df['Qx'].iloc[i], df['Qy'].iloc[i], WS=WS, verbose=verbose ))\n",
    "            #print 'D_x = ', (PS_WSoptics( df['Qx'].iloc[i], df['Qy'].iloc[i], WS=WS, verbose=verbose )['D_x'])\n",
    "            df.loc[df.index[i],'dx']=PS_WSoptics( df['Qx'].iloc[i], df['Qy'].iloc[i], WS=WS, verbose=verbose )['D_x']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerous ways of calculating the emittance from dataframe variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emittance_df(ndf, WS='65.H', myFiles=None, beta=0.91444281513833, gamma=2.4708737618826, dp=8.7e-4, verbose=False):\n",
    "    df=ndf.copy()\n",
    "    a=df.columns\n",
    "    span=span_range(df,myFiles=myFiles)\n",
    "    \n",
    "    if WS[-1]=='V':\n",
    "        \n",
    "        if 'emittance V' not in a:\n",
    "            df['emittance V']=np.nan\n",
    "        if 'sig V' not in a:\n",
    "            df=profiles(df,WS=WS)  \n",
    "        if 'bety' not in a:\n",
    "            df=twiss(df, WS=WS, verbose=verbose)\n",
    "        for i in span:\n",
    "            df.loc[df.index[i],'emittance V']=beta*gamma*(df['sig V'].iloc[i]**2)/df['bety'].iloc[i]\n",
    "            print 'Emittance ', i, ' = ', beta*gamma*(df['sig V'].iloc[i]**2)/df['bety'].iloc[i]\n",
    "    else:    \n",
    "        if 'emittance H' not in a:\n",
    "            df['emittance H']=np.nan\n",
    "        if 'sig H' not in a:\n",
    "            df=profiles(df,WS=WS)\n",
    "        if 'betx' not in a:\n",
    "            df=twiss(df,WS=WS)\n",
    "        for i in span:\n",
    "            df.loc[df.index[i],'emittance H noDisp']=beta*gamma*(df['sig H'].iloc[i]**2)/df['betx'].iloc[i]\n",
    "            df.loc[df.index[i],'emittance H']=beta*gamma*(df['sig H'].iloc[i]**2-(df['dx'].iloc[i]*1000)**2*dp**2)/df['betx'].iloc[i]\n",
    "            print 'Emittance ', i, ' = ', beta*gamma*(df['sig H'].iloc[i]**2-(df['dx'].iloc[i]*1000)**2*dp**2)/df['betx'].iloc[i]\n",
    "    return df\n",
    "\n",
    "def emittance_df_2(ndf, WS='65.H', myFiles=None, beta=0.91444281513833, gamma=2.4708737618826, dp=8.7e-4, verbose=False):\n",
    "    df=ndf.copy()\n",
    "    a=df.columns\n",
    "    span=span_range(df,myFiles=myFiles)\n",
    "    \n",
    "    if WS[-1]=='V':\n",
    "        if 'bety' not in a:\n",
    "            df=twiss(df, WS=WS, verbose=verbose)\n",
    "        for i in span:\n",
    "            df.loc[df.index[i],'emittance V 2ndMoment']=beta*gamma*(df['2ndMoment V'].iloc[i]**2)/df['bety'].iloc[i]\n",
    "            print 'Emittance from 2nd moment', i, ' = ', beta*gamma*(df['2ndMoment V'].iloc[i]**2)/df['bety'].iloc[i]\n",
    "    else:\n",
    "        if 'betx' not in a:\n",
    "            df=twiss(df, WS=WS, verbose=verbose)\n",
    "        for i in span:\n",
    "            df.loc[df.index[i],'emittance H 2ndMoment noDisp']=beta*gamma*(df['2ndMoment H'].iloc[i]**2)/df['betx'].iloc[i]\n",
    "            df.loc[df.index[i],'emittance H 2ndMoment']=beta*gamma*(df['2ndMoment H'].iloc[i]**2-(df['dx'].iloc[i]*1000)**2*dp**2)/df['betx'].iloc[i]\n",
    "            print 'Emittance from 2nd moment', i, ' = ', beta*gamma*(df['2ndMoment H'].iloc[i]**2-(df['dx'].iloc[i]*1000)**2*dp**2)/df['betx'].iloc[i]\n",
    "    return df\n",
    "\n",
    "def core_emittance_df(ndf, WS='65.H', myFiles=None, beta=0.91444281513833, gamma=2.4708737618826, dp=8.7e-4, verbose=False):\n",
    "    df=ndf.copy()\n",
    "    a=df.columns    \n",
    "    \n",
    "    if WS[-1]=='V':\n",
    "        if 'Core emittance V' not in a:\n",
    "            df['Core emittance V']=np.nan\n",
    "        span=span_range(df,myFiles=myFiles)\n",
    "        if 'bety' not in a:\n",
    "            df=twiss(df, WS=WS, verbose=verbose)\n",
    "        for i in span:\n",
    "            df.loc[df.index[i],'Core emittance V']=beta*gamma*(df['Core sig V'].iloc[i]**2)/df['bety'].iloc[i]\n",
    "            print 'Emittance ', i, ' = ', beta*gamma*(df['Core sig V'].iloc[i]**2)/df['bety'].iloc[i]\n",
    "\n",
    "    else:\n",
    "        if 'Core emittance H' not in a:\n",
    "            df['Core emittance H']=np.nan\n",
    "        span=span_range(df,myFiles=myFiles)\n",
    "        if 'betx' not in a:\n",
    "            df=twiss(df, WS=WS, verbose=verbose)\n",
    "        for i in span:\n",
    "            df.loc[df.index[i],'Core emittance H noDisp']=beta*gamma*(df['Core sig H'].iloc[i]**2)/df['betx'].iloc[i]\n",
    "            df.loc[df.index[i],'Core emittance H']=beta*gamma*(df['Core sig H'].iloc[i]**2-(df['dx'].iloc[i]*1000)**2*dp**2)/df['betx'].iloc[i]\n",
    "            print 'Emittance ', i, ' = ', beta*gamma*(df['Core sig H'].iloc[i]**2-(df['dx'].iloc[i]*1000)**2*dp**2)/df['betx'].iloc[i]\n",
    "    return df\n",
    "\n",
    "# Override original due to a bug?\n",
    "def core_emittance_df_2(ndf, WS='65.H', myFiles=None, beta=0.91444281513833, gamma=2.4708737618826, dp=8.7e-4, verbose=False):\n",
    "    df=ndf.copy()\n",
    "    a=df.columns    \n",
    "    \n",
    "    if WS[-1]=='V':\n",
    "        span=span_range(df,myFiles=myFiles)\n",
    "        if 'bety' not in a:\n",
    "            df=twiss(df, WS=WS, verbose=verbose)\n",
    "        for i in span:\n",
    "            df.loc[df.index[i],'Core emittance V 2ndMoment']=beta*gamma*(df['Core 2ndMoment V'].iloc[i]**2)/df['bety'].iloc[i]\n",
    "            print 'Emittance ', i, ' = ', beta*gamma*(df['sig V'].iloc[i]**2)/df['bety'].iloc[i]\n",
    "\n",
    "        \n",
    "    else:        \n",
    "        span=span_range(df,myFiles=myFiles)\n",
    "        if 'betx' not in a:\n",
    "            df=twiss(df, WS=WS, verbose=verbose)\n",
    "        for i in span:\n",
    "            df.loc[df.index[i],'Core emittance H 2ndMoment noDisp']=beta*gamma*(df['Core 2ndMoment H'].iloc[i]**2)/df['betx'].iloc[i]\n",
    "            df.loc[df.index[i],'Core emittance H 2ndMoment']=beta*gamma*(df['Core 2ndMoment H'].iloc[i]**2-(df['dx'].iloc[i]*1000)**2*dp**2)/df['betx'].iloc[i]\n",
    "            print 'Emittance ', i, ' = ', beta*gamma*(df['Core 2ndMoment H'].iloc[i]**2-(df['dx'].iloc[i]*1000)**2*dp**2)/df['betx'].iloc[i]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function to round a number to n significant figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_sig(x, sig=4):\n",
    "    return round(x, sig-int(floor(log10(abs(x))))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load particles from a pyorbit output matfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def particles_from_matfile(filename):\n",
    "    d = dict()\n",
    "    sio.loadmat(filename, mdict=d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function to find peak of wirescanner/simulation profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peakfinder_old (x_dat, y_dat, tolerance = 1, verbose=False):\n",
    "    \n",
    "    # Find maximum\n",
    "    max_y = max(y_dat)\n",
    "    if verbose: print '\\n\\tMAX(y_dat) = ', max_y   \n",
    "    \n",
    "    # Assume peak as centre\n",
    "    index = np.where(y_dat == max_y)[0][0]\n",
    "\n",
    "    # Check if centre is near 0.0\n",
    "    if abs(x_dat[index]) < tolerance:\n",
    "        if verbose: print '\\tx_dat[index] = ', x_dat[index]\n",
    "    \n",
    "    # Manually find 0 index\n",
    "    else:\n",
    "        if verbose: print '\\tindex from y_dat peak not within tolerance of',tolerance,'mm. \\n\\ttry manual search'\n",
    "        \n",
    "        index = -1\n",
    "        final_index = -1\n",
    "        for i in xrange(len(x_dat)):\n",
    "            index = index + 1\n",
    "            if x_dat[i] < 0.0:\n",
    "                final_index = index\n",
    "                break\n",
    "                \n",
    "        index = final_index\n",
    "        if verbose: print '\\tindex = ', index       \n",
    "       \n",
    "    if verbose: print '\\tindex of x_dat = ', x_dat[index],' is ', index\n",
    "        \n",
    "    # Take y=0 +/- 3 points and find mean \n",
    "    mean_dat = [y_dat[index-3],  y_dat[index-2],  y_dat[index-1], y_dat[index],  y_dat[index+1],  y_dat[index+2],  y_dat[index+3]]\n",
    "    mean_7 = np.mean(mean_dat)\n",
    "    if verbose: print '\\tMean of peak point +/- 3 points = ', mean_7   \n",
    "    \n",
    "    if abs( abs(mean_7 - max_y) / mean_7 ) > 0.2:\n",
    "        print '\\tWARNING: difference between mean and max_y > 20% = ', abs( abs(mean_7 - max_y) / mean_7 )\n",
    "        print '\\t using peak value'\n",
    "        mean_7 = max_y\n",
    "    return mean_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peakfinder (x_dat, y_dat, peak_points = 30, tolerance = 1.0E-3, verbose=False):\n",
    "    \n",
    "    # Find maximum\n",
    "    max_y = max(y_dat)\n",
    "    if verbose: print '\\n\\tMAX(y_dat) = ', max_y   \n",
    "    \n",
    "    # Assume peak as centre\n",
    "    index = np.where(y_dat == max_y)[0][0]\n",
    "    if verbose: print '\\tMAX(y_dat) index = ', index  \n",
    "    \n",
    "    print '\\tabs(x_dat[index]) = ', abs(x_dat[index])\n",
    "\n",
    "    # Manually find 0 index\n",
    "    index = -1\n",
    "    final_index = -1\n",
    "    \n",
    "    if x_dat[0] > 0.:\n",
    "        for i in xrange(len(x_dat)):\n",
    "            index = index + 1     \n",
    "            if x_dat[i] < 0.0:\n",
    "                final_index = index\n",
    "                break\n",
    "    else:\n",
    "         for i in xrange(len(x_dat)):\n",
    "            index = index + 1     \n",
    "            if x_dat[i] > 0.0:\n",
    "                final_index = index\n",
    "                break       \n",
    "\n",
    "    index = final_index\n",
    "    if verbose: print '\\tindex = ', index       \n",
    "       \n",
    "    if verbose: print '\\tindex of x_dat = ', x_dat[index],' is ', index\n",
    "        \n",
    "    # Find mean around some range of points about the centre\n",
    "    peak_points_range = (2*peak_points + 1)\n",
    "    print '\\nTaking the average of centre ', peak_points_range, ' points'\n",
    "    av_indices = np.linspace(-peak_points, peak_points, peak_points_range)\n",
    "    \n",
    "    mean_dat = []\n",
    "    for av_id in av_indices:\n",
    "        mean_dat.append(y_dat[index+int(av_id)])    \n",
    "    mean_11 = np.mean(mean_dat)\n",
    "    if verbose: print '\\tMean of ',peak_points_range,' points about centre = ', mean_11\n",
    "        \n",
    "    # If the calculated peak is 30% smaller than the absolute peak it is likely the peak is off centre\n",
    "    # perform the same averaging around the absolute peak\n",
    "    if abs( abs(mean_11 - max_y) / mean_11 ) > 0.3:\n",
    "        print '\\tWARNING: difference between mean and max_y > 30% = ', abs( abs(mean_11 - max_y) / mean_11 )\n",
    "        print '\\t using peak value'\n",
    "        #mean_11 = max_y\n",
    "        index = np.where(y_dat == max_y)[0][0]\n",
    "        mean_dat = []\n",
    "        \n",
    "        for av_id in av_indices:\n",
    "            mean_dat.append(y_dat[index+int(av_id)])    \n",
    "        mean_11 = np.mean(mean_dat)\n",
    "        if verbose: print '\\tMean of ',peak_points_range,' points about centre = ', mean_11\n",
    "        \n",
    "    return mean_11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find indices of peak in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_factor_of_peak_indices(x_data, y_data, fac, verbose = False):\n",
    "    indices = []\n",
    "    first = int(0)\n",
    "    second = int(0)    \n",
    "    \n",
    "    indx_max = np.argmax(y_data)\n",
    "    peak = y_data[indx_max]\n",
    "    \n",
    "    for i in xrange(len(y_data)):\n",
    "        if y_data[i] > peak*fac:\n",
    "            if verbose: print 'half peak of ', y_data[i] , ' found at index ', i\n",
    "            first = i\n",
    "            break\n",
    "        \n",
    "    for i in reversed(xrange(len(y_data))):\n",
    "        if y_data[i] > peak*fac:\n",
    "            if verbose: print 'half peak of ', y_data[i] , ' found at index ', i\n",
    "            second = i\n",
    "            break\n",
    "            \n",
    "    indices.append(first)\n",
    "    indices.append(second)\n",
    "    \n",
    "    return indices\n",
    "\n",
    "def find_half_peak_indices(x_data, y_data, verbose = False):\n",
    "    indices = []\n",
    "    first = int(0)\n",
    "    second = int(0)    \n",
    "    \n",
    "    indx_max = np.argmax(y_data)\n",
    "    peak = y_data[indx_max]\n",
    "    \n",
    "    for i in xrange(len(y_data)):\n",
    "        if y_data[i] > peak/2:\n",
    "            if verbose: print 'half peak of ', y_data[i] , ' found at index ', i\n",
    "            first = i\n",
    "            break\n",
    "        \n",
    "    for i in reversed(xrange(len(y_data))):\n",
    "        if y_data[i] > peak/2:\n",
    "            if verbose: print 'half peak of ', y_data[i] , ' found at index ', i\n",
    "            second = i\n",
    "            break\n",
    "    \n",
    "    indices.append(first)\n",
    "    indices.append(second)\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot MD profiles against simulation profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_profiles_MD_cf_Sims(d, df, md_points, vertical = 0, main_label = '', bins=1000, sim_label='Simulation', md_label='MD'):\n",
    "\n",
    "    # One colour per data point\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(df)))\n",
    "\n",
    "    fig=plt.figure(figsize=(8, 4), dpi= 200, facecolor='w', edgecolor='k');\n",
    "    multi = 1/1E-3\n",
    "    sim_norm = 1.0\n",
    "    \n",
    "    plt.clf()\n",
    "    if vertical: x, bins_, p = plt.hist(d['particles']['y'][0][0][0]*multi, bins = bins, density=True, histtype=u'step', lw=0, color='k')\n",
    "    else: x, bins_, p = plt.hist(d['particles']['x'][0][0][0]*multi, bins = bins, density=True, histtype=u'step', lw=0, color='k')\n",
    "           \n",
    "    for i in md_points:\n",
    "        \n",
    "        # Normalisation so all plots peak at y=1\n",
    "        if vertical: df_norm = 1/peakfinder(np.array(df['position V'].iloc[i]), np.array(df['profile V'].iloc[i]))\n",
    "        else:        df_norm = 1/peakfinder(np.array(df['position H'].iloc[i]), np.array(df['profile H'].iloc[i]))\n",
    "        sim_norm = 1/peakfinder(np.array(bins_[:-1]), np.array(x))\n",
    "        \n",
    "        lab = md_label + str(i)\n",
    "        if vertical: plt.plot(df['position V'].iloc[i], np.array(df['profile V'].iloc[i])*df_norm, color=colors[i], label = md_label, lw=0.5)\n",
    "        else:        plt.plot(df['position H'].iloc[i], np.array(df['profile H'].iloc[i])*df_norm, color=colors[i], label = md_label, lw=0.5)\n",
    "    \n",
    "    bins_ = np.array(bins_[:-1]) + (abs(bins_[0]-bins_[1])/2)\n",
    "\n",
    "    plt.plot(bins_, x*sim_norm, lw=2, color='k', label=sim_label)\n",
    "    \n",
    "    \n",
    "    plt.ylabel('Arbitrary Unit')\n",
    "    if vertical: plt.xlabel('y [mm]')\n",
    "    else: plt.xlabel('x [mm]')\n",
    "    plt.legend(fontsize='x-small')\n",
    "    plt.grid();\n",
    "    plt.title(main_label)\n",
    "    savename = main_label + '.png'\n",
    "    fig.savefig(savename);\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot MD profiles againsta  comparison of different space charge method simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_profiles_cf_sc_models(df, md_points, d1, vertical=0, d2=None, d3=None, main_label = '', save_name = 'test', bins=1000, sim_labels=None, md_label='Measurement', plot_md=False):\n",
    "\n",
    "    # One colour per data point\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(df)))\n",
    "\n",
    "    fig=plt.figure(figsize=(8, 4), dpi= 200, facecolor='w', edgecolor='k');\n",
    "    multi = 1/1E-3\n",
    "    \n",
    "    if sim_labels is None:\n",
    "        if d2 is not None:\n",
    "            sim_labels = ['2.5D','nLK']\n",
    "        elif d3 is not None:\n",
    "            sim_labels = ['2.5D','nLK','SbS']            \n",
    "        else:\n",
    "            sim_labels = ['2.5D']\n",
    "    \n",
    "    plt.clf()\n",
    "    if vertical: x1, bins_1, p1 = plt.hist(d1['particles']['y'][0][0][0]*multi, bins = bins, density=True, histtype=u'step', lw=0, color='k')\n",
    "    else: x1, bins_1, p1 = plt.hist(d1['particles']['x'][0][0][0]*multi, bins = bins, density=True, histtype=u'step', lw=0, color='k')\n",
    "        \n",
    "    if d2 is not None:\n",
    "        plt.clf()\n",
    "        if vertical: x2, bins_2, p2 = plt.hist(d2['particles']['y'][0][0][0]*multi, bins = bins, density=True, histtype=u'step', lw=0, color='r')\n",
    "        else: x2, bins_2, p2 = plt.hist(d2['particles'][\n",
    "            'x'][0][0][0]*multi, bins = bins, density=True, histtype=u'step', lw=0, color='r')\n",
    "        \n",
    "        if d3 is not None:\n",
    "            plt.clf()\n",
    "            if vertical: x3, bins_3, p3 = plt.hist(d3['particles']['y'][0][0][0]*multi, bins = bins, density=True, histtype=u'step', lw=0, color='b')\n",
    "            else: x3, bins_3, p3 = plt.hist(d3['particles']['x'][0][0][0]*multi, bins = bins, density=True, histtype=u'step', lw=0, color='b')\n",
    "   \n",
    "        \n",
    "    norm1 = 1/peakfinder(np.array(bins_1[:-1]), np.array(x1), verbose=True)\n",
    "    if d2 is not None: norm2 = 1/peakfinder(np.array(bins_2[:-1]), np.array(x2), verbose=True)\n",
    "    if d3 is not None: norm3 = 1/peakfinder(np.array(bins_3[:-1]), np.array(x3), verbose=True)\n",
    "        \n",
    "    if plot_md:\n",
    "        for i in md_points:\n",
    "            # Normalisation so all plots peak at y=1\n",
    "            if vertical:   multi2 = 1/peakfinder(np.array(df0['position V'].iloc[i]), np.array(df0['profile V'].iloc[i]))\n",
    "            else:          multi2 = 1/peakfinder(np.array(df0['position H'].iloc[i]), np.array(df0['profile H'].iloc[i]))\n",
    "#             multi2 = 1/max(np.array(df0['profile V'].iloc[i]))\n",
    "\n",
    "            lab = md_label + str(i)\n",
    "            if vertical: plt.plot(df0['position V'].iloc[i], np.array(df0['profile V'].iloc[i])*multi2, color='b', label = md_label, lw=1)\n",
    "            else: plt.plot(df0['position H'].iloc[i], np.array(df0['profile H'].iloc[i])*multi2, color='b', label = md_label, lw=1)\n",
    "\n",
    "    bins1 = np.array(bins_1[:-1]) + (abs(bins_1[0]-bins_1[1])/2)\n",
    "    plt.plot(bins1, x1*norm1, lw=2, color='r', label=sim_labels[0])\n",
    "    if d2 is not None: \n",
    "        bins2 = np.array(bins_2[:-1]) + (abs(bins_2[0]-bins_2[1])/2)\n",
    "        plt.plot(bins2, x2*norm2, lw=2, color='r', label=sim_labels[1])\n",
    "    if d3 is not None: \n",
    "        bins3 = np.array(bins_3[:-1]) + (abs(bins_3[0]-bins_3[1])/2)\n",
    "        plt.plot(bins3, x3*norm3, lw=2, color='b', label=sim_labels[2])\n",
    "    \n",
    "    \n",
    "    if vertical: plt.xlim(-20, 20)\n",
    "    else: plt.xlim(-25, 25)\n",
    "    plt.ylim(-0.05, 1.1)\n",
    "    \n",
    "    plt.ylabel('Arbitrary Unit')\n",
    "    if vertical: plt.xlabel('y [mm]')\n",
    "    else: plt.xlabel('x [mm]')\n",
    "    plt.legend(fontsize='x-small')\n",
    "    plt.grid();\n",
    "    plt.title(main_label)\n",
    "    savename = save_name.replace(\" \", \"_\") + '.png'\n",
    "    fig.savefig(savename);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_profiles_cf_sc_models_single(df, md_points, d1, vertical=0, main_label = '', save_name = 'test', bins=1000, sim_labels=None, md_label='Measurement', plot_md=False):\n",
    "\n",
    "    # One colour per data point\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(df)))\n",
    "\n",
    "    fig=plt.figure(figsize=(6, 4), dpi= 200, facecolor='w', edgecolor='k');\n",
    "    multi = 1/1E-3\n",
    "    \n",
    "    if sim_labels is None:\n",
    "        if d2 is not None:\n",
    "            sim_labels = ['2.5D','nLK']\n",
    "        elif d3 is not None:\n",
    "            sim_labels = ['2.5D','nLK','SbS']            \n",
    "        else:\n",
    "            sim_labels = ['2.5D']\n",
    "    \n",
    "    plt.clf()\n",
    "    if vertical: x1, bins_1, p1 = plt.hist(d1['particles']['y'][0][0][0]*multi, bins = bins, density=True, histtype=u'step', lw=0, color='k')\n",
    "    else: x1, bins_1, p1 = plt.hist(d1['particles']['x'][0][0][0]*multi, bins = bins, density=True, histtype=u'step', lw=0, color='k')\n",
    "        \n",
    "    norm1 = 1/peakfinder(np.array(bins_1[:-1]), np.array(x1), peak_points = 30, verbose=True)\n",
    "        \n",
    "    if plot_md:\n",
    "        for i in md_points:\n",
    "            # Normalisation so all plots peak at y=1\n",
    "            if vertical:   multi2 = 1/peakfinder(np.array(df0['position V'].iloc[i]), np.array(df0['profile V'].iloc[i]), peak_points = 10)\n",
    "            else:          multi2 = 1/peakfinder(np.array(df0['position H'].iloc[i]), np.array(df0['profile H'].iloc[i]), peak_points = 10)\n",
    "\n",
    "            lab = md_label + str(i)\n",
    "            if vertical: plt.plot(df0['position V'].iloc[i], np.array(df0['profile V'].iloc[i])*multi2, color='b', lw=1)\n",
    "            else: plt.plot(df0['position H'].iloc[i], np.array(df0['profile H'].iloc[i])*multi2, color='b', lw=1)\n",
    "\n",
    "    bins1 = np.array(bins_1[:-1]) + (abs(bins_1[0]-bins_1[1])/2)\n",
    "    plt.plot(bins1, x1*norm1, lw=2, color='r')\n",
    "    \n",
    "    if vertical: plt.xlim(-20, 20)\n",
    "    else: plt.xlim(-25, 25)\n",
    "    plt.ylim(-0.05, 1.1)\n",
    "    \n",
    "    plt.ylabel('Arbitrary Unit')\n",
    "    if vertical: plt.xlabel('y [mm]')\n",
    "    else: plt.xlabel('x [mm]')\n",
    "    #plt.legend(fontsize='x-small')\n",
    "    \n",
    "    custom_lines = [Line2D([0], [0], color='b', lw=4),Line2D([0], [0], color='r', lw=4)] \n",
    "    \n",
    "    if len(md_points) is 1:\n",
    "        num_measurements = str(len(md_points)) + ' Measurement'        \n",
    "    else:\n",
    "        num_measurements = str(len(md_points)) + ' Measurements'\n",
    "    plt.legend(custom_lines, [num_measurements, 'LEQ Simulation'], fontsize='small')\n",
    "    \n",
    "    plt.grid();\n",
    "    plt.title(main_label)\n",
    "    savename = save_name.replace(\" \", \"_\") + '.png'\n",
    "    fig.savefig(savename);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
